{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First GAN\n",
    "This is my first implementation of a working Generative Adversarial Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing all necessary libraries\n",
    "`hyperdash` can be removed. Just don't forget to remove all the code that uses it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijsvMX3BQc4m"
   },
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as tcl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from hyperdash import Experiment # To view the training from my phone, CAN BE REMOVED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. All the necessary functions\n",
    "These are functions for:\n",
    "1. Sampling from a Gaussian distribution,\n",
    "2. Creating the generator,\n",
    "3. Creating the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jWMuClaKQsNl"
   },
   "outputs": [],
   "source": [
    "# Helper funcs\n",
    "def sample_z(m, n):\n",
    "    return np.random.normal(0., 0.1, size=[m, n]) # Sampling from a Gaussian distribution\n",
    "\n",
    "\n",
    "start = 28 # Starting dimensions of the image in the deconv-net\n",
    "depth = 1024 // 8 # Depth of the image in the deconv-net\n",
    "\n",
    "training_session_number = 4 # Current training session number\n",
    "\n",
    "# NOTE: Before running this notebook, be sure to look through the code and fill in the missing code in the\n",
    "# training loop and after it.\n",
    "\n",
    "# NOTE: To just generate images from a saved model, do not run the training loop. Run the session written at\n",
    "# the bottom.\n",
    "\n",
    "\n",
    "# Generator model\n",
    "def gen(z, reuse):\n",
    "    with tf.variable_scope(\"Generator\", reuse=reuse):\n",
    "        net = tcl.fully_connected(z, start * start * depth, activation_fn=tf.nn.leaky_relu)\n",
    "        net = tf.reshape(net, (-1, start, start, depth))\n",
    "        return tcl.conv2d_transpose(net, 1, start, normalizer_fn=tcl.batch_norm, activation_fn=tf.nn.tanh)\n",
    "\n",
    "\n",
    "# Discriminator model\n",
    "def dis(x, reuse):\n",
    "    with tf.variable_scope(\"Discriminator\", reuse=reuse):\n",
    "        net = tcl.conv2d(x, depth // 2, start, 2, padding=\"SAME\", normalizer_fn=tcl.batch_norm, activation_fn=tf.nn.leaky_relu)\n",
    "        net = tcl.dropout(net, 0.85)\n",
    "        net = tcl.flatten(net)\n",
    "        return tcl.fully_connected(net, 1, activation_fn=tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hTiMCUKhoPKQ"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = (X_train / 127.5) - 1. # Normalize the dataset in range [-1, 1] for training\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Graph\n",
    "\n",
    "### 4. Creating the placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gqMgHyKETJ19"
   },
   "outputs": [],
   "source": [
    "# Creating the placeholders\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_train.shape[1], X_train.shape[2], 1], name=\"image_input\")\n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100], name=\"latent_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Getting the outputs from both the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gbyxQdWTvSs"
   },
   "outputs": [],
   "source": [
    "# Get outputs from nets\n",
    "gen_imgs = gen(Z, False)\n",
    "d_real = dis(X, False)\n",
    "d_fake = dis(gen_imgs, True)\n",
    "\n",
    "# Add generated images to summary\n",
    "tf.summary.image(\"GEN_IMAGES\", gen_imgs[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Computing the loss\n",
    "Here, I am using the \"-log D\" trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfRBNDfVgxY2"
   },
   "outputs": [],
   "source": [
    "# Computing the loss\n",
    "d_loss = -tf.reduce_mean(tf.log(d_real) + tf.log(1. - d_fake))\n",
    "g_loss = -tf.reduce_mean(tf.log(d_fake))\n",
    "\n",
    "# Add losses to summary\n",
    "tf.summary.scalar(\"DISC_LOSS\", d_loss)\n",
    "tf.summary.scalar(\"GEN_LOSS\", g_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Getting the variables for both the networks to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NfAIkuh_Hhnf"
   },
   "outputs": [],
   "source": [
    "# Getting variables\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Generator\")\n",
    "dis_var = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Creating optimizers to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jCw6UayaiMX9"
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "g_opt = tf.train.AdamOptimizer(0.001).minimize(g_loss, var_list=gen_vars)\n",
    "d_opt = tf.train.MomentumOptimizer(0.001, 0.001).minimize(d_loss, var_list=dis_var, name=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Merging all summaries to be viewed using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge summaries\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eekSytsqml-2"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Creating a saver to save the model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Training the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "j3VQw4t_kKCm",
    "outputId": "510c04b6-cb61-43b8-da37-d6c848f296fa"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "# Creating experiment for monitoring\n",
    "exp = Experiment(\"GAN Test Final\")\n",
    "\n",
    "# Creating session to train the model\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./model/{}/logs\".format(), sess.graph) # Summary writer\n",
    "    sess.run(tf.global_variables_initializer()) # Initialize all variables\n",
    "    \n",
    "    saver.restore(sess, \"./model/{}/saved/model_ckpt_9.ckpt\".format())\n",
    "    print(\"Starting where the last training session left off.\")\n",
    "  \n",
    "    for i in range(10000):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size) # Pick random indices from X\n",
    "        imgs = X_train[idx] # Pick random images from X\n",
    "    \n",
    "        # Get the losses\n",
    "        _, d_loss_curr, s_str = sess.run([d_opt, d_loss, summary_op], feed_dict={X: imgs, Z: sample_z(batch_size, 100)})\n",
    "        _, g_loss_curr = sess.run([g_opt, g_loss], feed_dict={Z: sample_z(batch_size, 100)})\n",
    "        \n",
    "        # Write the summary of the iteration\n",
    "        writer.add_summary(s_str, i)\n",
    "    \n",
    "        # Log\n",
    "        print(\"Iteration: {}, D_LOSS: {}, G_LOSS: {}\".format(i + 1, d_loss_curr, g_loss_curr))\n",
    "        \n",
    "        # Save the model every 1000 iterations\n",
    "        if i % 500 == 0:\n",
    "            save_path = saver.save(sess, \"./model/{}/saved/model_ckpt_{}.ckpt\".format(, str(i // 1000)))\n",
    "            print(\"Saved model {} at: {}\".format(training_session_number, save_path))\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# End experiment and stop sending to my phone\n",
    "exp.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Generating sampless from the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6r1pbow3zWM"
   },
   "outputs": [],
   "source": [
    "genned_imgs = None\n",
    "\n",
    "# Generate image from the generator\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./model/{}/saved/model_ckpt_9.ckpt\".format(training_session_number - 1))\n",
    "    genned_imgs = sess.run(gen_imgs, feed_dict={Z: sample_z(10, 100)}) # Generating 10 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Reshaping and rescaling the images back to the original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lBapKMvx4WXs"
   },
   "outputs": [],
   "source": [
    "# Reshaping the image\n",
    "genned_imgs = np.reshape(genned_imgs, (10, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rescale to 0-255 and convert to uint8\n",
    "genned_imgs = (genned_imgs + 1.) * 127.5\n",
    "genned_imgs = genned_imgs.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Saving the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "FSwpBk-F4hH0",
    "outputId": "848884d5-87c3-42e5-ee51-988a5fa4683a"
   },
   "outputs": [],
   "source": [
    "# Saving generated images\n",
    "for i in range(genned_imgs.shape[0]):\n",
    "    imsave(\"./generated/imgs/img_{}.png\".format(i + 1), genned_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GANTest2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
